# -*- coding: utf-8 -*-
"""Wiley Django.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_UZDVk9KlHZKjCmo_RZkHXEtP015jyJE
"""

!pip install git+https://github.com/microsoft/dowhy.git
import dowhy
from dowhy import CausalModel

import numpy as np
import pandas as pd

# Import data from Github

url="https://raw.githubusercontent.com/sunnysong14/ContinualPerformanceValidityTSE2022/main/data/django.csv"

df = pd.read_csv(url, sep=",")

print(df.shape)
df.head()

df.describe()

import graphviz
!apt install libgraphviz-dev
!pip install pygraphviz

df.columns

df1=df[['nd','la','ld', 'lt', 'age','nuc', 'entrophy','ndev','exp', 'rexp','sexp','nf','ns','days_to_first_fix']]

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
df_scaled = ss.fit_transform(df1)

data_scaled_df = pd.DataFrame(df_scaled, columns = df1.columns)
data_scaled_df.head()

print(data_scaled_df.shape)

# df1 = df1.dropna()
# To replace NAN with mean values
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')  # Or use other strategies like 'median'
df1 = pd.DataFrame(imputer.fit_transform(df1), columns=df1.columns)

# Import necessary libraries
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from causallearn.search.ConstraintBased.PC import pc
from causallearn.utils.GraphUtils import GraphUtils
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import io


# Replace NAN with mean values in data_scaled_df before applying pc function
imputer = SimpleImputer(strategy='mean')  # Or use other strategies like 'median'
data_scaled_df_imputed = pd.DataFrame(imputer.fit_transform(data_scaled_df), columns=data_scaled_df.columns)

labels = [f'{col}' for i, col in enumerate(data_scaled_df_imputed.columns)]
data = data_scaled_df_imputed.to_numpy() # use the imputed data

cg = pc(data)

# Visualization using pydot
from causallearn.utils.GraphUtils import GraphUtils
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import io

pyd = GraphUtils.to_pydot(cg.G, labels=labels)
pyd.write_png('img_causal_PC_Django.png')
tmp_png = pyd.create_png(f="png")
fp = io.BytesIO(tmp_png)
img = mpimg.imread(fp, format='png')
plt.axis('off')
plt.imshow(img)
plt.show()

"""GES algorithm"""

import numpy as np
from causallearn.search.ScoreBased.GES import ges
from causallearn.utils.GraphUtils import GraphUtils
import matplotlib.pyplot as plt
import io

# Sample data
#X = np.random.rand(100, 5)  # 100 samples, 5 features
labels = [f'{col}' for i, col in enumerate(data_scaled_df_imputed.columns)]
data = data_scaled_df_imputed.to_numpy()

# Run GES with BIC score
#record_bic = ges(X, score_func='local_score_BIC')
record_bic = ges(data_scaled_df_imputed, score_func='local_score_BIC')

# Run GES with generalized score
#record_gen = ges(X, score_func='local_score_cv_general')
#record_gen = ges(data_scaled_df, score_func='local_score_cv_general')

# Visualization
def plot_graph(record, title):
    #pyd = GraphUtils.to_pydot(record['G'])
    pyd = GraphUtils.to_pydot(record['G'], labels=labels)
    tmp_png = pyd.create_png(f="png")
    fp = io.BytesIO(tmp_png)
    img = plt.imread(fp, format='png')
    plt.axis('off')
    plt.imshow(img)
    plt.title(title)
    plt.show()

plot_graph(record_bic, 'GES with BIC Score')
#plot_graph(record_gen, 'GES with Generalized Score')

df1=df[['nuc','entrophy','ndev','exp', 'rexp','sexp','nf','ns','days_to_first_fix']]

"""Step 1: Define causal model In the first step, we need to define a so-called structural causal model (SCM), which is a combination of the causal graph and the underlying generative models describing the data generation proces"""

import networkx as nx

causal_graph = nx.DiGraph([('sexp', 'days_to_first_fix'),
                           ('nf', 'ns'),
                           #('entrophy','ndev'),
                           ('nf', 'nuc'),
                           ('nuc', 'days_to_first_fix'),
                           ('entrophy','exp'),
                           ('rexp', 'days_to_first_fix'),
                           ('ndev', 'days_to_first_fix'),
                           ('ns', 'entrophy'),
                           ('rexp','days_to_first_fix'),
                           ('entrophy','nuc'),
                            ('entrophy','ndev'),
                           ('entrophy','exp'),
                           ('ndev','nuc'),
                           ('ndev','rexp'),
                           ('entrophy', 'days_to_first_fix'),
                           ('exp', 'sexp')])

import networkx as nx
from dowhy import CausalModel

# Impute missing values in df1 before creating the CausalModel
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')  # Or use other strategies like 'median'
df1 = pd.DataFrame(imputer.fit_transform(df1), columns=df1.columns)

# Replace inf with large finite values
df1 = df1.replace([np.inf, -np.inf], np.nan)
df1 = pd.DataFrame(imputer.fit_transform(df1), columns=df1.columns)


# Create a copy of the causal graph without the causal mechanisms
causal_graph_for_gml = causal_graph.copy()
for node in causal_graph_for_gml.nodes:
    causal_graph_for_gml.nodes[node].clear()  # Remove node attributes
for u, v in causal_graph_for_gml.edges:
    causal_graph_for_gml.edges[u, v].clear()  # Remove edge attributes

# Convert the cleaned causal_graph to a GML string
graph_gml = "\n".join(nx.generate_gml(causal_graph_for_gml))

# With graph
model = CausalModel(
    data=df1,
    treatment="ndev",   #ndev, #nuc,#sexp, #rexp, #ns, #nf
    outcome="days_to_first_fix",
    graph=graph_gml  # Pass the GML string instead of the DiGraph object
)

model.view_model()

"""Fitting the SCM to Data. With the data at hand and the graph constructed earlier, we can now evaluate the performance of DAG:"""

from dowhy import gcm
# Create and fit your causal model
causal_model = gcm.StructuralCausalModel(causal_graph)
gcm.auto.assign_causal_mechanisms(causal_model, data_scaled_df_imputed)
gcm.fit(causal_model, data_scaled_df_imputed)

# Evaluate the causal model
evaluation_results = gcm.evaluate_causal_model(causal_model, data_scaled_df_imputed)

# Print the evaluation results
print(evaluation_results)

#Arrow Strength
import numpy as np
from dowhy.gcm.util.plotting import plot # Import the plot function

# Note: The percentage conversion only makes sense for purely positive attributions.
def convert_to_percentage(value_dictionary):
    total_absolute_sum = np.sum([abs(v) for v in value_dictionary.values()])
    return {k: abs(v) / total_absolute_sum * 100 for k, v in value_dictionary.items()}


# Use causal_model instead of scm
arrow_strengths = gcm.arrow_strength(causal_model, target_node='days_to_first_fix')

# Assuming 'plot' is defined elsewhere and takes these arguments
plot(causal_graph,
     causal_strengths=convert_to_percentage(arrow_strengths),
     figure_size=[15, 10])


# or save the graph
pyd.write_png('Django_arrow_strength.png')

identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)
print(identified_estimand)

"""### Estimand : 1 # ns
Estimand name: backdoor
Estimand expression:
  d                        
─────(E[days_to_first_fix])
d[nf]                      
Estimand assumption 1, Unconfoundedness: If U→{nf} and U→days_to_first_fix then P(days_to_first_fix|nf,,U) = P(days_to_first_fix|nf,)

### Estimand : 2
Estimand name: iv
No such variable(s) found!

### Estimand : 3
Estimand name: frontdoor
Estimand expression:
 ⎡                     d                                           ∂           ↪
E⎢───────────────────────────────────────────(days_to_first_fix)⋅─────([entrop ↪
 ⎣d[entrophy  ndev  rexp  sexp  exp  nuc  ns]                    ∂[nf]         ↪

↪                                     ⎤
↪ hy  ndev  rexp  sexp  exp  nuc  ns])⎥
↪                                     ⎦
Estimand assumption 1, Full-mediation: entrophy,ndev,rexp,sexp,exp,nuc,ns intercepts (blocks) all directed paths from nf to d,a,y,s,_,t,o,_,f,i,r,s,t,_,f,i,x.
Estimand assumption 2, First-stage-unconfoundedness: If U→{nf} and U→{entrophy,ndev,rexp,sexp,exp,nuc,ns} then P(entrophy,ndev,rexp,sexp,exp,nuc,ns|nf,U) = P(entrophy,ndev,rexp,sexp,exp,nuc,ns|nf)
Estimand assumption 3, Second-stage-unconfoundedness: If U→{entrophy,ndev,rexp,sexp,exp,nuc,ns} and U→days_to_first_fix then P(days_to_first_fix|entrophy,ndev,rexp,sexp,exp,nuc,ns, nf, U) = P(days_to_first_fix|entrophy,ndev,rexp,sexp,exp,nuc,ns, nf)

### Estimand : 4
Estimand name: general_adjustment
Estimand expression:
  d                        
─────(E[days_to_first_fix])
d[nf]                      
Estimand assumption 1, Unconfoundedness: If U→{nf} and U→days_to_first_fix then P(days_to_first_fix|nf,,U) = P(days_to_first_fix|nf,)

Estimand expression: for rexp
   d                              
───────(E[days_to_first_fix|ndev])
d[rexp]

### Estimand : 1
Estimand name: backdoor
Estimand expression:
   d                             
───────(E[days_to_first_fix|exp])
d[sexp]

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d                                       
──────(E[days_to_first_fix|entrophy,ndev])
d[nuc]
"""

estimate= model.estimate_effect(
 identified_estimand,
 method_name='backdoor.linear_regression',
 confidence_intervals=True,
  test_significance=True
)

print(f'Estimate of causal effect: {estimate}')

"""Estimate of causal effect: *** Causal Estimate *** #nf

## Identified estimand
Estimand type: EstimandType.NONPARAMETRIC_ATE

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d                        
─────(E[days_to_first_fix])
d[nf]                      
Estimand assumption 1, Unconfoundedness: If U→{nf} and U→days_to_first_fix then P(days_to_first_fix|nf,,U) = P(days_to_first_fix|nf,)

## Realized estimand
b: days_to_first_fix~nf
Target units: ate

## Estimate
Mean value: -0.20864460390509976
p-value: [0.00241046]
95.0% confidence interval: [[-0.34340613 -0.07388307]]

## Identified estimand for exp
Estimand type: EstimandType.NONPARAMETRIC_ATE

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d                                  
──────(E[days_to_first_fix|entrophy])
d[exp]                               
Estimand assumption 1, Unconfoundedness: If U→{exp} and U→days_to_first_fix then P(days_to_first_fix|exp,entrophy,U) = P(days_to_first_fix|exp,entrophy)

## Realized estimand
b: days_to_first_fix~exp+entrophy+exp*rexp+exp*nuc+exp*ndev
Target units:

## Estimate
Mean value: 0.006265863300569663
p-value: [1.46718507e-28]
95.0% confidence interval: (np.float64(0.004589630597564565), np.float64(0.008079781841217937))
### Conditional Estimates
__categorical__rexp  __categorical__nuc  __categorical__ndev
(-473.726, 1.004]    (-0.001, 11.0]      (-0.001, 9.0]          0.014102
                                         (9.0, 25.0]            0.012782
                                         (25.0, 68.0]           0.010245
                                         (68.0, 165.0]          0.002861
                                         (165.0, 272.0]        -0.007516
                                                                  ...   
(1.586, 17281.0]     (193.0, 10416.0]    (-0.001, 9.0]          0.013326
                                         (9.0, 25.0]            0.012310
                                         (25.0, 68.0]           0.009858
                                         (68.0, 165.0]          0.003656
                                         (165.0, 272.0]        -0.009211

## Identified estimand for nf
Estimand type: EstimandType.NONPARAMETRIC_ATE

### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d                        
─────(E[days_to_first_fix])
d[nf]                      
Estimand assumption 1, Unconfoundedness: If U→{nf} and U→days_to_first_fix then P(days_to_first_fix|nf,,U) = P(days_to_first_fix|nf,)

## Realized estimand
b: days_to_first_fix~nf
Target units: ate

## Estimate
Mean value: -0.20864460390509976
p-value: [0.00241046]
95.0% confidence interval: [[-0.34340613 -0.07388307]]

#ns
### Estimand : 1
Estimand name: backdoor
Estimand expression:
  d                           
─────(E[days_to_first_fix|nf])
d[ns]                         
Estimand assumption 1, Unconfoundedness: If U→{ns} and U→days_to_first_fix then P(days_to_first_fix|ns,nf,U) = P(days_to_first_fix|ns,nf)

## Realized estimand
b: days_to_first_fix~ns+nf
Target units: ate

## Estimate
Mean value: 24.244457731771703
p-value: [6.37213158e-14]
95.0% confidence interval: [[17.91200628 30.57690918]]

### Estimand : 1 rexp
Estimand name: backdoor
Estimand expression:
   d                              
───────(E[days_to_first_fix|ndev])
d[rexp]                           
Estimand assumption 1, Unconfoundedness: If U→{rexp} and U→days_to_first_fix then P(days_to_first_fix|rexp,ndev,U) = P(days_to_first_fix|rexp,ndev)

## Realized estimand
b: days_to_first_fix~rexp+ndev+rexp*nuc+rexp*sexp+rexp*exp
Target units:

## Estimate
Mean value: 0.004542352300944685
p-value: [0.15045974]
95.0% confidence interval: (np.float64(-0.02094134476234899), np.float64(0.031198424394688118))
### Conditional Estimates
__categorical__nuc  __categorical__sexp  __categorical__exp
(-0.001, 11.0]      (-0.001, 16.0]       (-0.001, 53.4]       -0.011449
                                         (53.4, 471.0]        -0.011713
                                         (471.0, 1537.2]      -0.012607
                                         (1537.2, 4099.0]     -0.014853
                                         (4099.0, 22615.5]    -0.022871
                                                                 ...   
(193.0, 10416.0]    (461.0, 1310.0]      (471.0, 1537.2]       0.044406
                                         (1537.2, 4099.0]      0.046584
                                         (4099.0, 22615.5]     0.040314
                    (1310.0, 18366.0]    (1537.2, 4099.0]      0.044999
                                         (4099.0, 22615.5]     0.053420

### Estimand : 1 for sexp
Estimand name: backdoor
Estimand expression:
   d                             
───────(E[days_to_first_fix|exp])
d[sexp]                          
Estimand assumption 1, Unconfoundedness: If U→{sexp} and U→days_to_first_fix then P(days_to_first_fix|sexp,exp,U) = P(days_to_first_fix|sexp,exp)

## Realized estimand
b: days_to_first_fix~sexp+exp+sexp*rexp+sexp*nuc+sexp*ndev
Target units:

## Estimate
Mean value: 0.01666988606083919
p-value: [6.24174263e-43]
95.0% confidence interval: (np.float64(0.011720438204008587), np.float64(0.022554938734799634))
### Conditional Estimates
__categorical__rexp  __categorical__nuc  __categorical__ndev
(-473.726, 1.004]    (-0.001, 11.0]      (-0.001, 9.0]          0.038342
                                         (9.0, 25.0]            0.034731
                                         (25.0, 68.0]           0.027806
                                         (68.0, 165.0]          0.007646
                                         (165.0, 272.0]        -0.020680
                                                                  ...   
(1.586, 17281.0]     (193.0, 10416.0]    (-0.001, 9.0]          0.035745
                                         (9.0, 25.0]            0.032931
                                         (25.0, 68.0]           0.025802
                                         (68.0, 165.0]          0.008966
                                         (165.0, 272.0]        -0.026212
Length: 125, dtype: float64

### Estimand : 1 for nuc
Estimand name: backdoor
Estimand expression:
  d                                       
──────(E[days_to_first_fix|entrophy,ndev])
d[nuc]                                    

## Realized estimand
b: days_to_first_fix~nuc+entrophy+ndev+nuc*rexp+nuc*sexp+nuc*exp
Target units:

## Estimate
Mean value: -0.027980826643812406
p-value: [0.00183629]
95.0% confidence interval: (np.float64(-0.041255669137314044), np.float64(-0.014445705271469933))
### Conditional Estimates
__categorical__rexp  __categorical__sexp  __categorical__exp
(-473.726, 1.004]    (-0.001, 16.0]       (-0.001, 53.4]       -0.030344
                                          (53.4, 471.0]        -0.029987
                                          (471.0, 1537.2]      -0.027288
                                          (1537.2, 4099.0]     -0.020892
                                          (4099.0, 22615.5]     0.021495
                                                                  ...   
(1.586, 17281.0]     (461.0, 1310.0]      (471.0, 1537.2]      -0.028427
                                          (1537.2, 4099.0]     -0.025505
                                          (4099.0, 22615.5]    -0.014660
                     (1310.0, 18366.0]    (1537.2, 4099.0]     -0.031614
                                          (4099.0, 22615.5]    -0.028258

### Estimand : 1 For ndev
Estimand name: backdoor
Estimand expression:
   d                                  
───────(E[days_to_first_fix|entrophy])
d[ndev]                               
Estimand assumption 1, Unconfoundedness: If U→{ndev} and U→days_to_first_fix then P(days_to_first_fix|ndev,entrophy,U) = P(days_to_first_fix|ndev,entrophy)

## Realized estimand
b: days_to_first_fix~ndev+entrophy+ndev*sexp+ndev*exp
Target units:

## Estimate
Mean value: -0.7301556332324424
p-value: [3.46179525e-114]
95.0% confidence interval: (np.float64(-0.7778736711806857), np.float64(-0.6854505182014918))
### Conditional Estimates
__categorical__sexp  __categorical__exp
(-0.001, 16.0]       (-0.001, 53.4]       -0.728206
                     (53.4, 471.0]        -0.727202
                     (471.0, 1537.2]      -0.720393
                     (1537.2, 4099.0]     -0.703339
                     (4099.0, 22615.5]    -0.624695
(16.0, 146.0]        (-0.001, 53.4]       -0.728695
                     (53.4, 471.0]        -0.728358
                     (471.0, 1537.2]      -0.724140
                     (1537.2, 4099.0]     -0.705566
                     (4099.0, 22615.5]    -0.659531
(146.0, 461.0]       (53.4, 471.0]        -0.731448
                     (471.0, 1537.2]      -0.728600
                     (1537.2, 4099.0]     -0.716285
                     (4099.0, 22615.5]    -0.673158
(461.0, 1310.0]      (53.4, 471.0]        -0.738058
                     (471.0, 1537.2]      -0.738364
                     (1537.2, 4099.0]     -0.727583
                     (4099.0, 22615.5]    -0.690998
(1310.0, 18366.0]    (1537.2, 4099.0]     -0.756644
                     (4099.0, 22615.5]    -0.747549
dtype: float64

Refutation
"""

refutel_common_cause=model.refute_estimate(identified_estimand,estimate,"random_common_cause")
print(refutel_common_cause)

"""Refute: Add a random common cause #nf
Estimated effect:-0.20864460390509976
New effect:-0.20864145268287815
p value:0.8799999999999999

Refute: Add a random common cause #ns
Estimated effect:24.244457731771703
New effect:24.247351156831304
p value:0.8999999999999999

Refute: Add a random common cause # NUC
Estimated effect:-0.02798082664784829
New effect:-0.027985774568082603
p value:0.96

Refute: Add a random common cause #ndev
Estimated effect:-0.7301556332321582
New effect:-0.73014872814331
p value:0.9199999999999999

Refute: Add a random common cause sexp
Estimated effect:0.016669886060810768
New effect:0.016671056102103704
p value:0.96

Refute: Add a random common cause rexp
Estimated effect:0.004542352300887842
New effect:0.004551242927322221
p value:0.8999999999999999
"""

refutel_common_cause=model.refute_estimate(identified_estimand,estimate,"data_subset_refuter")
print(refutel_common_cause)

"""Refute: Use a subset of data # nf
Estimated effect:-0.20864460390509976
New effect:-0.2114369960610378
p value:0.94

Refute: Use a subset of data #ns
Estimated effect:24.244457731771703
New effect:24.244613443421848
p value:1.0

Refute: Use a subset of data #NUC
Estimated effect:-0.02798082664784829
New effect:-0.028809417639557466
p value:0.84

Refute: Use a subset of data #ndev
Estimated effect:-0.7301556332321582
New effect:-0.7296953086510228
p value:1.0

Refute: Use a subset of data
Estimated effect:0.016669886060810768
New effect:0.01659378775616176
p value:0.92

Refute: Use a subset of data rexp
Estimated effect:0.004542352300887842
New effect:0.004301585280406357
p value:0.98
"""

refutation = model.refute_estimate(identified_estimand, estimate, method_name="placebo_treatment_refuter", placebo_type="permute", num_simulations=100)
print(refutation)

"""Refute: Use a Placebo Treatment
Estimated effect:-0.20864460390509976
New effect:0.01540703631575468
p value:0.98

Refute: Use a Placebo Treatment #ns
Estimated effect:24.244457731771703
New effect:0.061017764099335355
p value:0.96

Refute: Use a Placebo Treatment #rexp
Estimated effect:0.004542352300887842
New effect:0.0019240467602094212
p value:0.72

Refute: Use a Placebo Treatment # NUC
Estimated effect:-0.02798082664784829
New effect:0.0006148754242641985
p value:0.94

Refute: Use a Placebo Treatment #ndev
Estimated effect:-0.7301556332321582
New effect:-0.007878890025344844
p value:0.86

Refute: Use a Placebo Treatment #sexp
Estimated effect:0.016669886060810768
New effect:-0.00012060130073280107
p value:0.9

We need to ensure that the dataframe used for the OLS regressions (df in this case) does not contain any NaN or infinite values in the columns being used in the models. We can achieve this by applying imputation or dropping rows with missing values specifically before performing these OLS calculations. Given that df was not explicitly imputed in the code leading up to this error, we should apply imputation to the relevant columns of df.
"""

# Step 1: Estimate effect of X on M
# Impute missing values in the relevant columns of df before using them in OLS
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')

# Apply imputation to 'nf' and 'nuc' columns in the main df
df[['nf', 'nuc']] = imputer.fit_transform(df[['nf', 'nuc']])

# Replace inf with large finite values in the relevant columns of df
df[['nf', 'nuc']] = df[['nf', 'nuc']].replace([np.inf, -np.inf], np.nan)
df[['nf', 'nuc']] = imputer.fit_transform(df[['nf', 'nuc']]) # Impute again after replacing inf


model_XM = sm.OLS(df["nuc"], sm.add_constant(df["nf"])).fit()
df["M_hat"] = model_XM.predict(sm.add_constant(df["nf"]))

# Impute missing values in the relevant columns of df before using them in the second OLS model
# Apply imputation to 'days_to_first_fix' and 'M_hat' columns in the main df
df[['days_to_first_fix', 'M_hat']] = imputer.fit_transform(df[['days_to_first_fix', 'M_hat']])

# Replace inf with large finite values in the relevant columns of df
df[['days_to_first_fix', 'M_hat']] = df[['days_to_first_fix', 'M_hat']].replace([np.inf, -np.inf], np.nan)
df[['days_to_first_fix', 'M_hat']] = imputer.fit_transform(df[['days_to_first_fix', 'M_hat']]) # Impute again after replacing inf


# Step 2: Estimate effect of M_hat on Y
model_MY = sm.OLS(df["days_to_first_fix"], sm.add_constant(df["M_hat"])).fit()
print("Estimated causal effect:", model_MY.params["M_hat"])

# Step 1: Estimate effect of X on M
# Impute missing values in the relevant columns of df before using them in OLS
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')

# Apply imputation to 'nf' and 'nuc' columns in the main df
df[['nf', 'entrophy']] = imputer.fit_transform(df[['nf', 'entrophy']])

# Replace inf with large finite values in the relevant columns of df
df[['nf', 'entrophy']] = df[['nf', 'entrophy']].replace([np.inf, -np.inf], np.nan)
df[['nf', 'entrophy']] = imputer.fit_transform(df[['nf', 'entrophy']]) # Impute again after replacing inf


model_XM = sm.OLS(df["entrophy"], sm.add_constant(df["nf"])).fit()
df["M_hat"] = model_XM.predict(sm.add_constant(df["nf"]))

# Impute missing values in the relevant columns of df before using them in the second OLS model
# Apply imputation to 'days_to_first_fix' and 'M_hat' columns in the main df
df[['days_to_first_fix', 'M_hat']] = imputer.fit_transform(df[['days_to_first_fix', 'M_hat']])

# Replace inf with large finite values in the relevant columns of df
df[['days_to_first_fix', 'M_hat']] = df[['days_to_first_fix', 'M_hat']].replace([np.inf, -np.inf], np.nan)
df[['days_to_first_fix', 'M_hat']] = imputer.fit_transform(df[['days_to_first_fix', 'M_hat']]) # Impute again after replacing inf


# Step 2: Estimate effect of M_hat on Y
model_MY = sm.OLS(df["days_to_first_fix"], sm.add_constant(df["M_hat"])).fit()
print("Estimated causal effect:", model_MY.params["M_hat"])